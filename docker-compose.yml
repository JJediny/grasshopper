geocoder:
  build: geocoder
  links:
    - lines
    - points
    - parser
  ports:
    - "8080:8080"
  environment:
    GRASSHOPPER_ADDRESSPOINTS_HOST: points
    GRASSHOPPER_ADDRESSPOINTS_PORT: 8081
    GRASSHOPPER_CENSUS_HOST: lines
    GRASSHOPPER_CENSUS_PORT: 8082
    GRASSHOPPER_PARSER_HOST: parser
    GRASSHOPPER_PARSER_PORT: 5000


lines:
  build: census
  links: 
    - elasticsearch
  ports:
    - "8082:8082"
  environment: &ES_JAVA_ENV
    ELASTICSEARCH_HOST: elasticsearch

    # Must override this PORT as Docker Compose autogenerates an envvar by the
    # same name, but of the format: tcp://172.17.1.146:9200.
    # Also, ES Java client uses port 9300, not REST API port 9200.
    ELASTICSEARCH_PORT: 9300


points:
  build: addresspoints
  links: 
    - elasticsearch
  ports:
    - "8081:8081"
  environment: *ES_JAVA_ENV


parser:
  build: ../grasshopper-parser
  ports:
    - "5000:5000"

loader:
  build: ../grasshopper-loader
  links:
    - elasticsearch
  #command: ./grasshopper-loader.js -d test/data/new_york.json

# Must be named "elasticsearch" to create expected ELASTICSEARCH_* envvars
elasticsearch:
  image: elasticsearch


ui:
  build: ../grasshopper-ui
  ports:
    - "80:80"
  links:
    - geocoder
    - lines
    - points
    - parser


influxdb:
  image: tutum/influxdb
  ports:
    - 8083:8083 # Admin Site
    - 8086:8086 # API
  environment:
    PRE_CREATE_DB: cadvisor
  

cadvisor:
  image: google/cadvisor
  ports:
    - "9090:8080"
  volumes:
    - /:/rootfs:ro
    - /var/run:/var/run:rw
    - /sys:/sys:ro
    - /var/lib/docker/:/var/lib/docker:ro
  links:
    - influxdb
  command: -storage_driver=influxdb -storage_driver_db=cadvisor -storage_driver_host=influxdb:8086


grafana:
  image: grafana/grafana
  ports:
    - 3000:3000
  links:
    - influxdb
  environment:
    INFLUXDB_HOST: influxdb
    INFLUXDB_PORT: 8086
    INFLUXDB_NAME: cadvisor

# Logspout setup taken from:
#   https://github.com/gliderlabs/logspout#route-all-container-output-to-remote-syslog
logspout:
  image: gliderlabs/logspout:master 
  ports:
    - "8000:8000"
  volumes: 
    - /var/run/docker.sock:/tmp/docker.sock
  links:
    - logstash
  environment:
    LOGSPOUT: ignore
    SYSLOG_FORMAT: rfc3164
  command: syslog://logstash:5514

logstash:
  image: logstash
  expose:
    - 5514
  links:
    - elasticsearch
  environment:
    LOGSPOUT: ignore
  command: >
    logstash -e '
    input { syslog{ port => 5514 } }
    filter { 
        grok { 
          match => { "message" => [
            "%{IP:http_client_ip} - - \[%{HTTPDATE:http_req_time}\] (.)%{WORD:http_req_method} %{URIPATH:uri_path}(?:%{URIPARAM:uri_params})? HTTP\/%{NUMBER:http_ver}(.) %{NUMBER:http_resp_code} %{NUMBER:http_resp_size} (.)-(.) (.)%{GREEDYDATA:http_client}(.)",
            "\[%{TIMESTAMP_ISO8601:log_time}\]\[%{LOGLEVEL:log_level}%{SPACE}\]\[%{DATA:log_source}%{SPACE}\]%{SPACE}\[%{DATA:es_node}\]%{SPACE}\[%{DATA:es_index}\]%{SPACE}%{GREEDYDATA:message}",
            "\[%{TIMESTAMP_ISO8601:log_time}\]\[%{LOGLEVEL:log_level}%{SPACE}\]\[%{DATA:thread_name}\]%{SPACE}%{GREEDYDATA:message}"
          ] }
          overwrite => ["message"]
        }
        kv { source => "uri_params" prefix => "uri_param_" field_split => "&?" }
    }
    output { elasticsearch { host => "elasticsearch" } }'

kibana:
  image: marcbachmann/kibana4
  environment:
    LOGSPOUT: ignore
  links:
    - elasticsearch
  ports:
    - "5601:5601"

